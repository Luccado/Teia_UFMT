{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMERICAN KESTREL', 'AMERICAN REDSTART', 'AMETHYST WOODSTAR', 'ANHINGA', 'BAR-TAILED GODWIT', 'BARN OWL', 'BARN SWALLOW', 'BEARDED BELLBIRD', 'BLACK NECKED STILT', 'BLACK SKIMMER', 'BLACK VULTURE', 'BLACKBURNIAM WARBLER', 'BLONDE CRESTED WOODPECKER', 'BOBOLINK', 'CAMPO FLICKER', 'CAPPED HERON', 'CAPUCHINBIRD', 'CINNAMON ATTILA', 'CINNAMON TEAL', 'CRANE HAWK', 'CREAM COLORED WOODPECKER', 'EASTERN MEADOWLARK', 'GREAT JACAMAR', 'GREAT KISKADEE', 'GREAT POTOO', 'GREAT XENOPS', 'GREY PLOVER', 'HARPY EAGLE', 'HORNED SUNGEM', 'HOUSE SPARROW', 'IVORY BILLED ARACARI', 'KING VULTURE', 'LAUGHING GULL', 'LIMPKIN', 'MANGROVE CUCKOO', 'ORNATE HAWK EAGLE', 'OSPREY', 'PEREGRINE FALCON', 'POMARINE JAEGER', 'PURPLE GALLINULE', 'PURPLE MARTIN', 'RED BILLED TROPICBIRD', 'RED KNOT', 'ROCK DOVE', 'ROSEATE SPOONBILL', 'RUFUOS MOTMOT', 'SAND MARTIN', 'SCARLET MACAW', 'SHORT BILLED DOWITCHER', 'SNOWY EGRET', 'SNOWY SHEATHBILL', 'SPANGLED COTINGA', 'SQUACCO HERON', 'STRIPED OWL', 'STRIPPED MANAKIN', 'SUNBITTERN', 'TROPICAL KINGBIRD', 'TURKEY VULTURE', 'VEERY', 'WATTLED CURASSOW', 'WHIMBREL', 'WOOD THRUSH', 'output']\n",
      "Found 49910 files belonging to 63 classes.\n",
      "Using 39928 files for training.\n",
      "Found 49910 files belonging to 63 classes.\n",
      "Using 9982 files for validation.\n",
      "Epoch 1/10\n",
      "1248/1248 [==============================] - 138s 108ms/step - loss: 1.3709 - accuracy: 0.7997 - val_loss: 5.7316 - val_accuracy: 0.8009\n",
      "Epoch 2/10\n",
      "1248/1248 [==============================] - 134s 108ms/step - loss: 0.9318 - accuracy: 0.8081 - val_loss: 0.8756 - val_accuracy: 0.8103\n",
      "Epoch 3/10\n",
      "1248/1248 [==============================] - 134s 107ms/step - loss: 0.8929 - accuracy: 0.8195 - val_loss: 0.7552 - val_accuracy: 0.8214\n",
      "Epoch 4/10\n",
      "1248/1248 [==============================] - 136s 109ms/step - loss: 0.9317 - accuracy: 0.8268 - val_loss: 0.7198 - val_accuracy: 0.8274\n",
      "Epoch 5/10\n",
      "1248/1248 [==============================] - 135s 108ms/step - loss: 0.6214 - accuracy: 0.8452 - val_loss: 0.7028 - val_accuracy: 0.8361\n",
      "Epoch 6/10\n",
      "1248/1248 [==============================] - 135s 108ms/step - loss: 0.5646 - accuracy: 0.8573 - val_loss: 248.3313 - val_accuracy: 0.8351\n",
      "Epoch 7/10\n",
      "1248/1248 [==============================] - 136s 109ms/step - loss: 0.6217 - accuracy: 0.8655 - val_loss: 0.6396 - val_accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "1248/1248 [==============================] - 135s 108ms/step - loss: 0.4794 - accuracy: 0.8793 - val_loss: 0.6141 - val_accuracy: 0.8527\n",
      "Epoch 9/10\n",
      "1248/1248 [==============================] - 135s 108ms/step - loss: 0.4085 - accuracy: 0.8899 - val_loss: 0.6269 - val_accuracy: 0.8593\n",
      "Epoch 10/10\n",
      "1248/1248 [==============================] - 135s 108ms/step - loss: 0.5391 - accuracy: 0.8867 - val_loss: 0.7272 - val_accuracy: 0.8294\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "namecheckpoint = 'TreinosTF/ResNet50V2/v40/model.{epoch:02d}-{val_accuracy:.2f}.h5' \n",
    "model_checkpoint_callback = ModelCheckpoint(namecheckpoint,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    # change output folder\n",
    " )\n",
    "# substitui sua base aqui\n",
    "data_dir = pathlib.Path(\"./dataset brasileiro/TREINO\")\n",
    " \n",
    "# Define the classes from the data_dir\n",
    "classes = pathlib.Path(data_dir).glob('*')\n",
    "classes = [x for x in classes if x.is_dir()]\n",
    "classes = sorted([x.stem for x in classes])\n",
    "print(classes)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "epochs = 10\n",
    "# Define the data directory\n",
    "\n",
    "# Create training dataset\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Create validation dataset\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model\n",
    "pre_trained_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
    "\n",
    "total_layers = len(pre_trained_model.layers)\n",
    "num_layers_to_freeze = int(0.4 * total_layers)\n",
    "for layer in pre_trained_model.layers[:num_layers_to_freeze]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = layers.Flatten()(pre_trained_model.output)\n",
    "predictions = layers.Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "model3 = Model(inputs=pre_trained_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model using the training dataset and validation dataset\n",
    "history = model3.fit(\n",
    "    dataset, \n",
    "    validation_data=validation_dataset, \n",
    "    epochs=epochs,\n",
    "    callbacks=[model_checkpoint_callback]  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 310 images belonging to 62 classes.\n",
      "9/9 [==============================] - 1s 45ms/step\n",
      "Total number of images: 288\n",
      "['AMERICAN KESTREL', 'AMERICAN REDSTART', 'AMETHYST WOODSTAR', 'ANHINGA', 'BAR-TAILED GODWIT', 'BARN OWL', 'BARN SWALLOW', 'BEARDED BELLBIRD', 'BLACK NECKED STILT', 'BLACK SKIMMER', 'BLACK VULTURE', 'BLACKBURNIAM WARBLER', 'BLONDE CRESTED WOODPECKER', 'BOBOLINK', 'CAMPO FLICKER', 'CAPPED HERON', 'CAPUCHINBIRD', 'CINNAMON ATTILA', 'CINNAMON TEAL', 'CRANE HAWK', 'CREAM COLORED WOODPECKER', 'EASTERN MEADOWLARK', 'GREAT JACAMAR', 'GREAT KISKADEE', 'GREAT POTOO', 'GREAT XENOPS', 'GREY PLOVER', 'HARPY EAGLE', 'HORNED SUNGEM', 'HOUSE SPARROW', 'IVORY BILLED ARACARI', 'KING VULTURE', 'LAUGHING GULL', 'LIMPKIN', 'MANGROVE CUCKOO', 'ORNATE HAWK EAGLE', 'OSPREY', 'PEREGRINE FALCON', 'POMARINE JAEGER', 'PURPLE GALLINULE', 'PURPLE MARTIN', 'RED BILLED TROPICBIRD', 'RED KNOT', 'ROCK DOVE', 'ROSEATE SPOONBILL', 'RUFUOS MOTMOT', 'SAND MARTIN', 'SCARLET MACAW', 'SHORT BILLED DOWITCHER', 'SNOWY EGRET', 'SNOWY SHEATHBILL', 'SPANGLED COTINGA', 'SQUACCO HERON', 'STRIPED OWL', 'STRIPPED MANAKIN', 'SUNBITTERN', 'TROPICAL KINGBIRD', 'TURKEY VULTURE', 'VEERY', 'WATTLED CURASSOW', 'WHIMBREL', 'WOOD THRUSH']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy\n",
    "from keras.models import load_model\n",
    "\n",
    "#model3 = load_model('./TreinosTF/MobileNetV2/v3/model.06-0.80.h5')\n",
    "\n",
    "# Defina os valores de altura e largura da imagem aqui\n",
    "img_height = 224  # Substitua pelo valor correto\n",
    "img_width = 224   # Substitua pelo valor correto\n",
    "\n",
    "# Defina o tamanho do lote (batch_size) aqui\n",
    "batch_size = 32  # Substitua pelo valor desejado\n",
    "\n",
    "test_datagen = ImageDataGenerator()  # Rescale pixel values to [0, 1]\n",
    "test_data_dir = \"./dataset brasileiro/TEST\"\n",
    "\n",
    "\n",
    "# Create a test generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),  # Adjust the target size to match your model's input size\n",
    "    batch_size=batch_size,  # Batch size for generating predictions\n",
    "    class_mode='categorical',  # Change this to 'binary' i  f you have a binary classification problem\n",
    "    shuffle=False  # Set to False to maintain the order of images\n",
    ")\n",
    "\n",
    "# Get the class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Calculate the number of images in the dataset\n",
    "num_images = len(test_generator.filenames)\n",
    "\n",
    "# Initialize empty lists to store images and true labels\n",
    "all_images = []\n",
    "all_true_labels = []\n",
    "\n",
    "# Loop through the generator to accumulate all images and true labels\n",
    "for i in range(num_images // batch_size):\n",
    "    images, true_labels = next(test_generator)\n",
    "    all_images.append(images)\n",
    "    all_true_labels.append(true_labels)\n",
    "\n",
    "# Concatenate the accumulated images and true labels\n",
    "all_images = np.concatenate(all_images)\n",
    "all_true_labels = np.concatenate(all_true_labels)\n",
    "\n",
    "# Make predictions using the model on all images\n",
    "predictions = model3.predict(all_images)\n",
    "\n",
    "# Now, you have predictions for all images in the test dataset\n",
    "print(\"Total number of images:\", len(all_images))\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 32 54  0 33 17  1  6 29 39  2 13 44 28 54  3  3  3  3  3  4  4  4 48\n",
      "  4  5 49 49 13  5  6  6  6  6  6  7 36  7  0  7 33  6  1  8 62 62 62 49\n",
      " 38 21 29 33  7 10 55 21 49  6 54 11 12 12 12 12 12 21 13 13 13 58 14 33\n",
      " 19  4 29 49 15 17 49 49 22 20 16 20 59 20 17 17 17 17 18 54 62 46 18 41\n",
      " 39 11  6 39 20  3 20 54 20 29 42 21 21 21 22 22 22 22 22 23 23 31 54 23\n",
      " 24 53 53 24 24 47 20 44 20 42  4 26  4 26 26 31 62 41 22 53 28 28 28 28\n",
      " 28  6 54 26 29 53 56 22 51 30 30  2 31 47 59  6 32 32 38 32 32 62 33 33\n",
      " 33  4 62 20 45 45 34 41 24 62  4 33 51 53 57 36  0 33 43 57 33 37 37 62\n",
      " 32 57 26 39 39 39 56 39  6  6  0 40 40 41 62 31 62 41 42 42 24 42  4 38\n",
      "  7 33  4 33 50 50 49 50 58 45 16 54 17 45 59 37 56 56 56 47 47 25 47 47\n",
      "  4 42 48 48  4 49 62 32 49 49 62 50 50 49 49 51 59 51 51 31 39 25 52 44\n",
      " 52 49  5 24 53 53 54 39 39 54 20  4 33 62 26 62 56 54 58 56 32 57 36 43]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lucca\\Desktop\\iaaa\\TransferLe.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucca/Desktop/iaaa/TransferLe.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Converta as probabilidades previstas em rótulos de classe\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucca/Desktop/iaaa/TransferLe.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m pred \u001b[39min\u001b[39;00m predictions:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucca/Desktop/iaaa/TransferLe.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     predicted_label \u001b[39m=\u001b[39m class_labels[np\u001b[39m.\u001b[39;49margmax(pred)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucca/Desktop/iaaa/TransferLe.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     predicted_labels\u001b[39m.\u001b[39mappend(predicted_label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucca/Desktop/iaaa/TransferLe.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Converta os rótulos verdadeiros one-hot em rótulos de classe\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inicialize as listas vazias para armazenar os rótulos previstos e verdadeiros\n",
    "predicted_labels = []\n",
    "labels_true = []\n",
    "\n",
    "# Converta as probabilidades previstas em rótulos de classe\n",
    "for pred in predictions:\n",
    "    predicted_label = class_labels[np.argmax(pred)]\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Converta os rótulos verdadeiros one-hot em rótulos de classe\n",
    "for true in true_labels:\n",
    "    true_label = class_labels[np.argmax(true)]\n",
    "    labels_true.append(true_label)\n",
    "\n",
    "# Calcule a precisão\n",
    "accuracy = np.mean(np.equal(predicted_labels, labels_true))\n",
    "accuracy_percentage = accuracy * 100\n",
    "\n",
    "print(\"Accuracy:\", accuracy_percentage, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.625 %\n"
     ]
    }
   ],
   "source": [
    "# Converta as probabilidades previstas em rótulos de classe (índices das classes)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Converta as etiquetas verdadeiras one-hot em rótulos de classe (índices das classes)\n",
    "true_labels = np.argmax(all_true_labels, axis=1)\n",
    "\n",
    "# Calcule a acurácia comparando os rótulos previstos com os rótulos verdadeiros\n",
    "accuracy = np.mean(np.equal(predicted_labels, true_labels))\n",
    "accuracy_percentage = accuracy * 100\n",
    "\n",
    "print(\"Accuracy:\", accuracy_percentage, \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
